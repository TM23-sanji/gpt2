{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 FineWeb-Edu Performance Analysis\n",
        "\n",
        "This notebook provides performance analysis visualizations including:\n",
        "- Token processing speed and throughput\n",
        "- GPU memory usage\n",
        "- Training efficiency metrics\n",
        "- Resource utilization over time\n",
        "- Cost and time estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install wandb matplotlib seaborn numpy pandas torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Performance Data\n",
        "\n",
        "Load training performance metrics including token processing speed and GPU memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_performance_data(use_wandb=False, project_name=\"gpt-fineweb-demo\", run_id=None):\n",
        "    \"\"\"\n",
        "    Load performance data from WandB or generate synthetic data.\n",
        "    \"\"\"\n",
        "    if use_wandb:\n",
        "        try:\n",
        "            api = wandb.Api()\n",
        "            if run_id:\n",
        "                run = api.run(f\"{project_name}/{run_id}\")\n",
        "            else:\n",
        "                runs = list(api.runs(project_name))\n",
        "                if len(runs) == 0:\n",
        "                    raise ValueError(f\"No runs found in project {project_name}\")\n",
        "                run = runs[0]\n",
        "            \n",
        "            history = run.history()\n",
        "            return history\n",
        "        except Exception as e:\n",
        "            print(f\"WandB API error: {e}\")\n",
        "            print(\"Generating synthetic performance data...\")\n",
        "            use_wandb = False\n",
        "    \n",
        "    if not use_wandb:\n",
        "        # Generate synthetic performance data\n",
        "        max_tokens = 200_000_000\n",
        "        log_interval = 20\n",
        "        tokens_per_step = 16 * 256\n",
        "        \n",
        "        steps = np.arange(0, max_tokens // tokens_per_step, log_interval)\n",
        "        tokens_seen = steps * tokens_per_step\n",
        "        \n",
        "        # Token processing speed: starts at ~4k, stabilizes around ~6-7k tok/s\n",
        "        base_speed = 4000\n",
        "        target_speed = 6500\n",
        "        tokens_per_sec = base_speed + (target_speed - base_speed) * (1 - np.exp(-tokens_seen / 20_000_000))\n",
        "        tokens_per_sec += np.random.normal(0, 300, len(tokens_per_sec))\n",
        "        \n",
        "        # GPU memory: starts low, increases as model warms up, then stabilizes\n",
        "        gpu_mem_gb = 3.5 + 0.5 * (1 - np.exp(-tokens_seen / 10_000_000)) + np.random.normal(0, 0.1, len(tokens_seen))\n",
        "        gpu_mem_gb = np.clip(gpu_mem_gb, 3.0, 4.5)\n",
        "        \n",
        "        # Loss for context\n",
        "        train_loss = 10.8 * np.exp(-tokens_seen / 50_000_000) + 4.19 * (1 - np.exp(-tokens_seen / 50_000_000))\n",
        "        train_loss += np.random.normal(0, 0.1, len(train_loss))\n",
        "        \n",
        "        data = pd.DataFrame({\n",
        "            'step': steps,\n",
        "            'tokens_seen': tokens_seen,\n",
        "            'loss': train_loss,\n",
        "            'tokens_per_sec': tokens_per_sec,\n",
        "            'gpu_mem_gb': gpu_mem_gb,\n",
        "        })\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    return None\n",
        "\n",
        "# Load performance data\n",
        "perf_data = load_performance_data(use_wandb=False)\n",
        "\n",
        "print(f\"Loaded {len(perf_data)} performance data points\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(perf_data.head())\n",
        "print(\"\\nPerformance Statistics:\")\n",
        "print(perf_data[['tokens_per_sec', 'gpu_mem_gb']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Token Processing Speed Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_processing_speed_analysis(perf_data, tokens_or_steps='tokens'):\n",
        "    \"\"\"\n",
        "    Analyze token processing speed over training.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    x = perf_data['tokens_seen'] if tokens_or_steps == 'tokens' else perf_data['step']\n",
        "    x_label = 'Tokens Seen' if tokens_or_steps == 'tokens' else 'Training Steps'\n",
        "    \n",
        "    # Plot 1: Speed over time\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(x, perf_data['tokens_per_sec'], color='#6A4C93', linewidth=2, alpha=0.8)\n",
        "    avg_speed = perf_data['tokens_per_sec'].mean()\n",
        "    median_speed = perf_data['tokens_per_sec'].median()\n",
        "    ax1.axhline(y=avg_speed, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_speed:,.0f} tok/s')\n",
        "    ax1.axhline(y=median_speed, color='g', linestyle='--', linewidth=2, label=f'Median: {median_speed:,.0f} tok/s')\n",
        "    ax1.set_xlabel(x_label, fontsize=12)\n",
        "    ax1.set_ylabel('Tokens per Second', fontsize=12)\n",
        "    ax1.set_title('Token Processing Speed Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    if tokens_or_steps == 'tokens':\n",
        "        ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
        "    \n",
        "    # Plot 2: Speed distribution\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.hist(perf_data['tokens_per_sec'], bins=50, color='#6A4C93', alpha=0.7, edgecolor='black')\n",
        "    ax2.axvline(x=avg_speed, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_speed:,.0f}')\n",
        "    ax2.axvline(x=median_speed, color='g', linestyle='--', linewidth=2, label=f'Median: {median_speed:,.0f}')\n",
        "    ax2.set_xlabel('Tokens per Second', fontsize=12)\n",
        "    ax2.set_ylabel('Frequency', fontsize=12)\n",
        "    ax2.set_title('Token Processing Speed Distribution', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Plot 3: Rolling average\n",
        "    ax3 = axes[1, 0]\n",
        "    window = max(1, len(perf_data) // 20)  # 5% window\n",
        "    rolling_avg = perf_data['tokens_per_sec'].rolling(window=window, center=True).mean()\n",
        "    ax3.plot(x, perf_data['tokens_per_sec'], color='#6A4C93', alpha=0.3, linewidth=1, label='Raw')\n",
        "    ax3.plot(x, rolling_avg, color='#C73E1D', linewidth=2, label=f'Rolling Avg (window={window})')\n",
        "    ax3.set_xlabel(x_label, fontsize=12)\n",
        "    ax3.set_ylabel('Tokens per Second', fontsize=12)\n",
        "    ax3.set_title('Token Processing Speed (with Rolling Average)', fontsize=14, fontweight='bold')\n",
        "    ax3.legend(fontsize=10)\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    if tokens_or_steps == 'tokens':\n",
        "        ax3.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
        "    \n",
        "    # Plot 4: Speed vs Loss (efficiency)\n",
        "    ax4 = axes[1, 1]\n",
        "    scatter = ax4.scatter(perf_data['loss'], perf_data['tokens_per_sec'], \n",
        "                         c=x, cmap='viridis', alpha=0.6, s=30)\n",
        "    ax4.set_xlabel('Training Loss', fontsize=12)\n",
        "    ax4.set_ylabel('Tokens per Second', fontsize=12)\n",
        "    ax4.set_title('Processing Speed vs Loss', fontsize=14, fontweight='bold')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=ax4, label=x_label.replace(' (M)', ''))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Plot processing speed analysis\n",
        "fig = plot_processing_speed_analysis(perf_data, tokens_or_steps='tokens')\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(f\"\\n=== Token Processing Speed Statistics ===\")\n",
        "print(f\"Mean: {perf_data['tokens_per_sec'].mean():,.0f} tokens/sec\")\n",
        "print(f\"Median: {perf_data['tokens_per_sec'].median():,.0f} tokens/sec\")\n",
        "print(f\"Std Dev: {perf_data['tokens_per_sec'].std():,.0f} tokens/sec\")\n",
        "print(f\"Min: {perf_data['tokens_per_sec'].min():,.0f} tokens/sec\")\n",
        "print(f\"Max: {perf_data['tokens_per_sec'].max():,.0f} tokens/sec\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_gpu_memory_analysis(perf_data, tokens_or_steps='tokens'):\n",
        "    \"\"\"\n",
        "    Analyze GPU memory usage over training.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    x = perf_data['tokens_seen'] if tokens_or_steps == 'tokens' else perf_data['step']\n",
        "    x_label = 'Tokens Seen' if tokens_or_steps == 'tokens' else 'Training Steps'\n",
        "    \n",
        "    # Plot 1: Memory usage over time\n",
        "    ax1 = axes[0]\n",
        "    ax1.plot(x, perf_data['gpu_mem_gb'], color='#F18F01', linewidth=2, alpha=0.8)\n",
        "    avg_mem = perf_data['gpu_mem_gb'].mean()\n",
        "    max_mem = perf_data['gpu_mem_gb'].max()\n",
        "    min_mem = perf_data['gpu_mem_gb'].min()\n",
        "    ax1.axhline(y=avg_mem, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_mem:.2f} GB')\n",
        "    ax1.axhline(y=max_mem, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'Max: {max_mem:.2f} GB')\n",
        "    ax1.axhline(y=min_mem, color='blue', linestyle='--', linewidth=1, alpha=0.7, label=f'Min: {min_mem:.2f} GB')\n",
        "    ax1.set_xlabel(x_label, fontsize=12)\n",
        "    ax1.set_ylabel('GPU Memory (GB)', fontsize=12)\n",
        "    ax1.set_title('GPU Memory Usage Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    if tokens_or_steps == 'tokens':\n",
        "        ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
        "    \n",
        "    # Plot 2: Memory distribution\n",
        "    ax2 = axes[1]\n",
        "    ax2.hist(perf_data['gpu_mem_gb'], bins=30, color='#F18F01', alpha=0.7, edgecolor='black')\n",
        "    ax2.axvline(x=avg_mem, color='r', linestyle='--', linewidth=2, label=f'Mean: {avg_mem:.2f} GB')\n",
        "    ax2.axvline(x=perf_data['gpu_mem_gb'].median(), color='g', linestyle='--', linewidth=2, \n",
        "               label=f'Median: {perf_data[\"gpu_mem_gb\"].median():.2f} GB')\n",
        "    ax2.set_xlabel('GPU Memory (GB)', fontsize=12)\n",
        "    ax2.set_ylabel('Frequency', fontsize=12)\n",
        "    ax2.set_title('GPU Memory Usage Distribution', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Plot GPU memory analysis\n",
        "if 'gpu_mem_gb' in perf_data.columns:\n",
        "    fig = plot_gpu_memory_analysis(perf_data, tokens_or_steps='tokens')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n=== GPU Memory Statistics ===\")\n",
        "    print(f\"Mean: {perf_data['gpu_mem_gb'].mean():.2f} GB\")\n",
        "    print(f\"Median: {perf_data['gpu_mem_gb'].median():.2f} GB\")\n",
        "    print(f\"Std Dev: {perf_data['gpu_mem_gb'].std():.2f} GB\")\n",
        "    print(f\"Min: {perf_data['gpu_mem_gb'].min():.2f} GB\")\n",
        "    print(f\"Max: {perf_data['gpu_mem_gb'].max():.2f} GB\")\n",
        "else:\n",
        "    print(\"GPU memory data not available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Time and Efficiency Estimates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_training_estimates(perf_data, total_tokens=200_000_000):\n",
        "    \"\"\"\n",
        "    Calculate training time estimates and efficiency metrics.\n",
        "    \"\"\"\n",
        "    avg_speed = perf_data['tokens_per_sec'].mean()\n",
        "    \n",
        "    # Time estimates\n",
        "    total_seconds = total_tokens / avg_speed\n",
        "    total_hours = total_seconds / 3600\n",
        "    total_days = total_hours / 24\n",
        "    \n",
        "    # Efficiency metrics\n",
        "    tokens_per_hour = avg_speed * 3600\n",
        "    tokens_per_day = tokens_per_hour * 24\n",
        "    \n",
        "    # Estimate for different token counts\n",
        "    token_targets = [50_000_000, 100_000_000, 200_000_000, 500_000_000, 1_000_000_000]\n",
        "    estimates = []\n",
        "    \n",
        "    for target in token_targets:\n",
        "        hours = target / tokens_per_hour\n",
        "        days = hours / 24\n",
        "        estimates.append({\n",
        "            'Tokens': f\"{target/1e6:.0f}M\",\n",
        "            'Hours': f\"{hours:.1f}\",\n",
        "            'Days': f\"{days:.2f}\",\n",
        "        })\n",
        "    \n",
        "    estimates_df = pd.DataFrame(estimates)\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Plot 1: Time estimates bar chart\n",
        "    ax1 = axes[0]\n",
        "    token_nums = [t/1e6 for t in token_targets]\n",
        "    hours_list = [t / tokens_per_hour for t in token_targets]\n",
        "    bars = ax1.barh([f\"{t:.0f}M\" for t in token_nums], hours_list, color='#2E86AB', alpha=0.7)\n",
        "    ax1.set_xlabel('Training Time (Hours)', fontsize=12)\n",
        "    ax1.set_ylabel('Token Target', fontsize=12)\n",
        "    ax1.set_title('Estimated Training Time by Token Count', fontsize=14, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # Add value labels\n",
        "    for i, (bar, hours) in enumerate(zip(bars, hours_list)):\n",
        "        ax1.text(hours, i, f' {hours:.1f}h', va='center', fontsize=10)\n",
        "    \n",
        "    # Plot 2: Throughput over time\n",
        "    ax2 = axes[1]\n",
        "    x = perf_data['tokens_seen']\n",
        "    cumulative_hours = x / tokens_per_hour\n",
        "    ax2.plot(x / 1e6, cumulative_hours, color='#06A77D', linewidth=2)\n",
        "    ax2.set_xlabel('Tokens Processed (Millions)', fontsize=12)\n",
        "    ax2.set_ylabel('Cumulative Training Time (Hours)', fontsize=12)\n",
        "    ax2.set_title('Cumulative Training Time', fontsize=14, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add annotation for 200M tokens\n",
        "    final_hours = total_tokens / tokens_per_hour\n",
        "    ax2.plot(total_tokens / 1e6, final_hours, 'ro', markersize=10)\n",
        "    ax2.annotate(f'{final_hours:.1f}h ({final_hours/24:.2f}d)', \n",
        "                xy=(total_tokens / 1e6, final_hours),\n",
        "                xytext=(10, 10), textcoords='offset points', fontsize=11,\n",
        "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    return fig, estimates_df, {\n",
        "        'avg_speed': avg_speed,\n",
        "        'total_hours': total_hours,\n",
        "        'total_days': total_days,\n",
        "        'tokens_per_hour': tokens_per_hour,\n",
        "        'tokens_per_day': tokens_per_day,\n",
        "    }\n",
        "\n",
        "# Calculate estimates\n",
        "fig, estimates_df, metrics = calculate_training_estimates(perf_data)\n",
        "\n",
        "print(f\"\\n=== Training Efficiency Metrics ===\")\n",
        "print(f\"Average Processing Speed: {metrics['avg_speed']:,.0f} tokens/sec\")\n",
        "print(f\"Tokens per Hour: {metrics['tokens_per_hour']:,.0f}\")\n",
        "print(f\"Tokens per Day: {metrics['tokens_per_day']:,.0f}\")\n",
        "print(f\"\\n=== Time Estimates for 200M Tokens ===\")\n",
        "print(f\"Total Time: {metrics['total_hours']:.2f} hours ({metrics['total_days']:.2f} days)\")\n",
        "\n",
        "print(\"\\n=== Time Estimates Table ===\")\n",
        "print(estimates_df.to_string(index=False))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comprehensive Performance Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_performance_dashboard(perf_data, tokens_or_steps='tokens'):\n",
        "    \"\"\"\n",
        "    Create a comprehensive performance dashboard.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 12))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "    \n",
        "    x = perf_data['tokens_seen'] if tokens_or_steps == 'tokens' else perf_data['step']\n",
        "    x_label = 'Tokens Seen (M)' if tokens_or_steps == 'tokens' else 'Training Steps'\n",
        "    \n",
        "    # 1. Processing speed (top left)\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax1.plot(x / 1e6, perf_data['tokens_per_sec'], color='#6A4C93', linewidth=2)\n",
        "    ax1.axhline(y=perf_data['tokens_per_sec'].mean(), color='r', linestyle='--', \n",
        "               label=f'Avg: {perf_data[\"tokens_per_sec\"].mean():,.0f}')\n",
        "    ax1.set_xlabel(x_label, fontsize=10)\n",
        "    ax1.set_ylabel('Tokens/sec', fontsize=10)\n",
        "    ax1.set_title('Processing Speed', fontsize=12, fontweight='bold')\n",
        "    ax1.legend(fontsize=9)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. GPU memory (top center)\n",
        "    if 'gpu_mem_gb' in perf_data.columns:\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(x / 1e6, perf_data['gpu_mem_gb'], color='#F18F01', linewidth=2)\n",
        "        ax2.axhline(y=perf_data['gpu_mem_gb'].mean(), color='r', linestyle='--',\n",
        "                   label=f'Avg: {perf_data[\"gpu_mem_gb\"].mean():.2f} GB')\n",
        "        ax2.set_xlabel(x_label, fontsize=10)\n",
        "        ax2.set_ylabel('GPU Memory (GB)', fontsize=10)\n",
        "        ax2.set_title('GPU Memory Usage', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(fontsize=9)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Loss for context (top right)\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    ax3.plot(x / 1e6, perf_data['loss'], color='#2E86AB', linewidth=2)\n",
        "    ax3.set_xlabel(x_label, fontsize=10)\n",
        "    ax3.set_ylabel('Loss', fontsize=10)\n",
        "    ax3.set_title('Training Loss', fontsize=12, fontweight='bold')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Speed vs Memory (middle left)\n",
        "    if 'gpu_mem_gb' in perf_data.columns:\n",
        "        ax4 = fig.add_subplot(gs[1, 0])\n",
        "        scatter = ax4.scatter(perf_data['gpu_mem_gb'], perf_data['tokens_per_sec'],\n",
        "                             c=x, cmap='viridis', alpha=0.6, s=30)\n",
        "        ax4.set_xlabel('GPU Memory (GB)', fontsize=10)\n",
        "        ax4.set_ylabel('Tokens/sec', fontsize=10)\n",
        "        ax4.set_title('Speed vs Memory', fontsize=12, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter, ax=ax4, label='Tokens (M)')\n",
        "    \n",
        "    # 5. Efficiency over time (middle center)\n",
        "    ax5 = fig.add_subplot(gs[1, 1])\n",
        "    # Efficiency = tokens/sec per GB of memory (if available)\n",
        "    if 'gpu_mem_gb' in perf_data.columns:\n",
        "        efficiency = perf_data['tokens_per_sec'] / perf_data['gpu_mem_gb']\n",
        "        ax5.plot(x / 1e6, efficiency, color='#06A77D', linewidth=2)\n",
        "        ax5.set_ylabel('Efficiency (tok/s per GB)', fontsize=10)\n",
        "    else:\n",
        "        ax5.plot(x / 1e6, perf_data['tokens_per_sec'], color='#06A77D', linewidth=2)\n",
        "        ax5.set_ylabel('Tokens/sec', fontsize=10)\n",
        "    ax5.set_xlabel(x_label, fontsize=10)\n",
        "    ax5.set_title('Training Efficiency', fontsize=12, fontweight='bold')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Cumulative tokens (middle right)\n",
        "    ax6 = fig.add_subplot(gs[1, 2])\n",
        "    cumulative_hours = x / (perf_data['tokens_per_sec'].mean() * 3600)\n",
        "    ax6.plot(x / 1e6, cumulative_hours, color='#A23B72', linewidth=2)\n",
        "    ax6.set_xlabel(x_label, fontsize=10)\n",
        "    ax6.set_ylabel('Cumulative Hours', fontsize=10)\n",
        "    ax6.set_title('Cumulative Training Time', fontsize=12, fontweight='bold')\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 7. Performance summary table (bottom, spans all columns)\n",
        "    ax7 = fig.add_subplot(gs[2, :])\n",
        "    ax7.axis('off')\n",
        "    \n",
        "    avg_speed = perf_data['tokens_per_sec'].mean()\n",
        "    total_tokens = perf_data['tokens_seen'].iloc[-1]\n",
        "    total_hours = total_tokens / (avg_speed * 3600)\n",
        "    \n",
        "    summary_data = {\n",
        "        'Metric': [\n",
        "            'Avg Processing Speed',\n",
        "            'Total Tokens Processed',\n",
        "            'Total Training Time',\n",
        "            'Tokens per Hour',\n",
        "            'Tokens per Day',\n",
        "        ],\n",
        "        'Value': [\n",
        "            f\"{avg_speed:,.0f} tokens/sec\",\n",
        "            f\"{total_tokens:,.0f}\",\n",
        "            f\"{total_hours:.2f} hours ({total_hours/24:.2f} days)\",\n",
        "            f\"{avg_speed * 3600:,.0f}\",\n",
        "            f\"{avg_speed * 3600 * 24:,.0f}\",\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    if 'gpu_mem_gb' in perf_data.columns:\n",
        "        summary_data['Metric'].insert(3, 'Avg GPU Memory')\n",
        "        summary_data['Value'].insert(3, f\"{perf_data['gpu_mem_gb'].mean():.2f} GB\")\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    table = ax7.table(cellText=summary_df.values, colLabels=summary_df.columns,\n",
        "                     cellLoc='left', loc='center', bbox=[0, 0, 1, 1])\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(1, 2)\n",
        "    ax7.set_title('Performance Summary Statistics', fontsize=14, fontweight='bold', pad=20)\n",
        "    \n",
        "    plt.suptitle('GPT-2 FineWeb-Edu Performance Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
        "    return fig\n",
        "\n",
        "# Create performance dashboard\n",
        "fig = create_performance_dashboard(perf_data, tokens_or_steps='tokens')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
